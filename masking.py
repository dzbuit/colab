
from transformers import AutoTokenizer, AutoModelForTokenClassification, pipeline
import re, os


from IPython.display import display, Markdown, Javascript
import ipywidgets as widgets


# âœ… ìƒ‰ìƒ íŒ”ë ˆíŠ¸ ìˆœí™˜ ë¦¬ìŠ¤íŠ¸
TAG_COLORS = ["#007bff", "#28a745", "#ffc107", "#17a2b8", "#6610f2", "#e83e8c", "#6f42c1"]

def render_mapping_colored(mapping):
    html_lines = []
    for idx, (tag, value) in enumerate(mapping.items()):
        color = TAG_COLORS[int(tag[1:4]) % len(TAG_COLORS)]  # N100 â†’ 100 â†’ mod ìƒ‰ìƒ
        html_line = f"<b style='color:{color}'>{tag}</b> â†’ <span>{value}</span><br>"
        html_lines.append(html_line)
    return "".join(html_lines)

def launch_masking_ui():
    """
    ipywidgets ê¸°ë°˜ ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹ UI
    """

    # === ì…ë ¥ ìƒì ===
    input_box = widgets.Textarea(
        value='',
        placeholder='ì˜ˆ: í™ê¸¸ë™ êµìˆ˜ë‹˜ì´ ì„œìš¸ëŒ€í•™êµì—ì„œ ê°•ì˜í•˜ì…¨ìŠµë‹ˆë‹¤.\nì´ë©”ì¼ì€ gil@example.comì…ë‹ˆë‹¤.',
        description='ì…ë ¥:',
        layout=widgets.Layout(width='100%', height='250px')
    )

    # === ì‹¤í–‰ ë²„íŠ¼ ===
    run_button = widgets.Button(description='ë§ˆìŠ¤í‚¹ ì‹¤í–‰', button_style='success')

    # === ì¶œë ¥ ìƒì ===
    output_box = widgets.Textarea(
        value='',
        description='ë§ˆìŠ¤í‚¹ ê²°ê³¼:',
        layout=widgets.Layout(width='100%', height='250px')
    )

    # === ë§¤í•‘ ìƒì (ì»¬ëŸ¬ HTMLë¡œ í‘œì‹œ)
    mapping_box = widgets.HTML(
        value='',
        placeholder='ë§¤í•‘ ì •ë³´ ì¶œë ¥ ì˜ì—­',
        layout=widgets.Layout(width='100%', height='150px', overflow='auto', border='1px solid lightgray')
    )

    # === ë³µì‚¬ ë²„íŠ¼ë“¤ ===
    copy_output_btn = widgets.Button(description="ğŸ“‹ ê²°ê³¼ ë³µì‚¬", button_style='info')
    copy_mapping_btn = widgets.Button(description="ğŸ“‹ ë§¤í•‘ ë³µì‚¬", button_style='info')

    # === ì¸ë¼ì¸ ë©”ì‹œì§€ í‘œì‹œ
    info_label = widgets.Label("")

    # === ë³µì‚¬ ë¡œì§ (í…ìŠ¤íŠ¸ë§Œ í´ë¦½ë³´ë“œì— ë³µì‚¬)
    def copy_to_clipboard(value, target):
        js = f"""
        navigator.clipboard.writeText(`{value}`);
        """
        display(Javascript(js))
        info_label.value = f"{target} ë³µì‚¬ë˜ì—ˆìŠµë‹ˆë‹¤."

    # ğŸ“Œ ë³µì‚¬ ì´ë²¤íŠ¸ ì—°ê²° (í…ìŠ¤íŠ¸ë§Œ ë³µì‚¬)
    copy_output_btn.on_click(lambda _: copy_to_clipboard(output_box.value, "ê²°ê³¼"))
    copy_mapping_btn.on_click(lambda _: copy_to_clipboard(mapping_box.plain_text, "ë§¤í•‘"))

    # === ì‹¤í–‰ ë¡œì§
    def on_run_clicked(_):
        result, mapping, mapping_text = full_masking_pipeline(input_box.value)
        output_box.value = result
        mapping_box.value = render_mapping_colored(mapping)  # HTML ì»¬ëŸ¬ í‘œì‹œìš©
        mapping_box.plain_text = mapping_text                # ë³µì‚¬ìš© í…ìŠ¤íŠ¸ ì €ì¥
        info_label.value = "ë§ˆìŠ¤í‚¹ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."

    # ğŸ“Œ ë²„íŠ¼ í´ë¦­ ì´ë²¤íŠ¸ ì—°ê²°
    run_button.on_click(on_run_clicked)

    # === UI ë Œë”ë§
    display(Markdown("### ë””ì§€í„¸ê¸°íšìš´ì˜ë¶€ ë¯¼ê°ì •ë³´ ë§ˆìŠ¤í‚¹ê¸°"))
    display(input_box)
    display(run_button)
    display(output_box)
    display(copy_output_btn)
    display(mapping_box)
    display(copy_mapping_btn)
    display(info_label)


# âœ… ëª¨ë¸ ë¡œë”© (Drive ë§ˆìš´íŠ¸ ì—†ì´ ê¸°ë³¸ HuggingFace ìºì‹œ ì‚¬ìš©)
model_name = "Leo97/KoELECTRA-small-v3-modu-ner"
# âœ… ëª¨ë¸ ë¡œë”© (ìºì‹œ ë””ë ‰í† ë¦¬ ê¸°ë³¸ê°’ ì‚¬ìš©)
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForTokenClassification.from_pretrained(model_name)

ner_pipeline = pipeline("ner", model=model, tokenizer=tokenizer, aggregation_strategy="simple")



 # âœ… í™•ì¥ëœ í˜¸ì¹­ ë¦¬ìŠ¤íŠ¸
COMMON_SUFFIXES = [
    # ğŸ“ ê°€ì •/ê´€ê³„ ê¸°ë°˜
    'ì–´ë¨¸ë‹ˆ', 'ì•„ë²„ì§€', 'ì—„ë§ˆ', 'ì•„ë¹ ', 'í˜•', 'ëˆ„ë‚˜', 'ì–¸ë‹ˆ', 'ì˜¤ë¹ ', 'ë™ìƒ',
    'ë”¸', 'ì•„ë“¤', 'ì¡°ì¹´', 'ì‚¬ì´Œ', 'ì´ëª¨', 'ê³ ëª¨', 'ì‚¼ì´Œ', 'ìˆ™ëª¨', 'ì™¸ì‚¼ì´Œ',
    'í• ë¨¸ë‹ˆ', 'í• ì•„ë²„ì§€', 'ì™¸í• ë¨¸ë‹ˆ', 'ì™¸í• ì•„ë²„ì§€', 'ì¥ëª¨', 'ì¥ì¸', 'ë©°ëŠë¦¬', 'ì‚¬ìœ„',
    'ë¶€ì¸', 'ì™€ì´í”„', 'ì‹ ë‘', 'ì˜¬ì¼€', 'í˜•ìˆ˜', 'ì œìˆ˜ì”¨', 'ë§¤í˜•', 'ì²˜ì œ', 'ì‹œëˆ„ì´',
    # ğŸ“ ì‚¬íšŒ/êµìœ¡/ì§ì—… í˜¸ì¹­
    'í•™ìƒ', 'ì´ˆë“±í•™ìƒ', 'ì¤‘í•™ìƒ', 'ê³ ë“±í•™ìƒ', 'ìˆ˜í—˜ìƒ', 'í•™ë¶€ëª¨', 'ì„ ìƒ', 'ì„ ìƒë‹˜', 'êµì‚¬',
    'êµê°', 'êµì¥', 'ë‹´ì„', 'ë°˜ì¥', 'ì¡°êµìˆ˜', 'êµìˆ˜', 'ì—°êµ¬ì›', 'ê°•ì‚¬', 'ë°•ì‚¬', 'ì„ì‚¬', 'í•™ì‚¬',
    'ë³´í˜¸ì', 'í”¼í•´ì', 'ì•„ë™', 'ì£¼ë¯¼', 'ë‹¹ì‚¬ì', 'ëŒ€ìƒì', 'ë‹´ë‹¹ì',
    # ğŸ“ ì§ì¥/ì¡°ì§ ì§ê¸‰
    'ëŒ€í‘œ', 'ì´ì‚¬', 'ì „ë¬´', 'ìƒë¬´', 'ë¶€ì¥', 'ì°¨ì¥', 'ê³¼ì¥', 'ëŒ€ë¦¬', 'ì‚¬ì›', 'íŒ€ì¥', 'ë³¸ë¶€ì¥',
    'ì„¼í„°ì¥', 'ì†Œì¥', 'ì‹¤ì¥', 'ì´ë¬´', 'ì§ì›', 'ë§¤ë‹ˆì €', 'ì§€ì ì¥', 'ì‚¬ë¬´ì¥',
    # ğŸ“ ì˜ë£Œ/ê¸°íƒ€
    'ì˜ì‚¬', 'ê°„í˜¸ì‚¬', 'ê°„ë³‘ì¸', 'ê¸°ì‚¬ë‹˜', 'ì–´ë¥´ì‹ ', 'ë‹˜', 'ì”¨'
]


# âœ… ë¬¸ì¥ ê¸°ë°˜ íŒ¨í„´ ì •ì˜ (NER ë³´ì™„ìš©)
EXPLICIT_NAME_PATTERNS = [
    r"([ê°€-í£]{2,4})[ ]?(ì”¨|ë‹˜|ì„ ìƒë‹˜|êµìˆ˜ë‹˜)?(ì´|ê°€)?\s?(ë§ì”€|ì „ë‹¬|ì—°ë½|ê°•ì˜|ì„¤ëª…|ì‘ì„±|ë³´ê³ |ë°œì–¸)\w*",
    r"([ê°€-í£]{2,4})[ ]?ì˜\s?(ê³„ì¢Œ|ì „í™”ë²ˆí˜¸|ì£¼ì†Œ|ì´ë©”ì¼|ë¹„ë°€ë²ˆí˜¸|ê³„ì •)\w*",
    r"([ê°€-í£]{2,4})[ ]?ì…ë‹ˆë‹¤[.]?",
    r"ì˜ˆê¸ˆì£¼[ëŠ”\s]*([ê°€-í£]{2,4})",
    r"ê³„ì •[ì˜\s]*ì£¼ì¸[ì€\s]*([ê°€-í£]{2,4})",
    r"ì‘ì„±ì[ëŠ”\s]*([ê°€-í£]{2,4})",
]


# âœ… ì‹¤ì „ê¸‰ ì¡°ì‚¬ ë¦¬ìŠ¤íŠ¸
COMMON_JOSA = [
    # âœ… ê¸°ë³¸ ì¡°ì‚¬
    'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì€', 'ëŠ”', 'ì˜', 'ë„',
    # âœ… ì²˜ì†Œ/ë°©í–¥/ëŒ€ìƒ
    'ì—', 'ì—ì„œ', 'ì—ê²Œ', 'ê»˜ì„œ', 'ìœ¼ë¡œ', 'ë¡œ', 'ë¶€í„°', 'ê¹Œì§€', 'í•œí…Œ',
    # âœ… ê°•ì¡°/ëŒ€ì¡°/ë¹„êµ
    'ë³´ë‹¤', 'ë³´ë‹¤ë„', 'ë§ˆì €', 'ì¡°ì°¨', 'ì¡°ì°¨ë„', 'ê¹Œì§€ë„', 'ë°–ì—', 'ë§Œí¼', 'ë§Œí¼ì€',
    'ì´ë¼ë„', 'ì´ë“ ì§€', 'ì´ë‚˜ë§ˆ', 'ì´ê±´', 'ì´ë€', 'ì´ë¼ì„œ', 'ì´ì§€ë§Œ',
    # âœ… ì—°ê²°í˜• ì¡°ì‚¬
    'ì´ë©°', 'ì´ë‚˜', 'ì´ê±°ë‚˜', 'ì´ë‹ˆê¹Œ', 'ì´ë¼ë©´', 'ì²˜ëŸ¼', 'ëŒ€ë¡œ', 'í•˜ê³ ', 'ê·¸ë¦¬ê³ ', 'ì™€', 'ê³¼',
    # âœ… ë³´ì¡°/ì¢…ê²°í˜• ì–´ë¯¸
    'ì´ê¸°ë„', 'ì´ì—ˆë˜', 'ì´ì—ˆì§€ë§Œ', 'ì´ì–´ì„œ', 'ì´ì—ˆë‹¤ë©´', 'ì¸', 'ì¼', 'ì„', 'ì´ë€', 'ì´ë¼ëŠ”',
    # âœ… íŠ¹ìˆ˜í˜• ì¡°ì‚¬/ì¡°í•©í˜•
    'ê°™ì€', 'ê°™ì•„ì„œ', 'ê¹Œì§€ëŠ”', 'ë¿ë§Œ ì•„ë‹ˆë¼', 'ì™€ëŠ”', 'ì™€ë„', 'í•˜ê³ ë„', 'ìœ¼ë¡œì„œ', 'ìœ¼ë¡œì¨'
]

# âœ… ì´ë¦„ ì¶”ì¶œ (NER + ë¬¸ì¥íŒ¨í„´ ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ)
def extract_names(text):
    ner_results = ner_pipeline(text)

    # âœ… ì‚¬ì „ ì •ì˜ëœ "ì‚¬ëŒì´ ì•„ë‹Œ í‘œí˜„" í•„í„°ë§ ëª©ë¡
    FORBIDDEN_NAME_TERMS = {
        "ë³´í˜¸ì", "ë‹´ë‹¹ì", "ëŒ€ìƒì", "í”¼í•´ì", "ì˜ì‚¬", "ê°„í˜¸ì‚¬", "í•™ìƒ",
        "ì£¼ë¯¼", "ì•„ë™", "ë§¤ë‹ˆì €", "ëŒ€í‘œ", "êµìˆ˜", "ê°•ì‚¬", "ì§ì›", "ì´ë¬´", "ì‚¬ë¬´ì¥"
    }

    # âœ… NER ê²°ê³¼ ê¸°ë°˜ ì´ë¦„ í›„ë³´ ìˆ˜ì§‘ (ê¸ˆì§€ì–´ ì œì™¸)
    names = [
        e["word"].replace("##", "").strip()
        for e in ner_results
        if e["entity_group"] == "PS"
        and e["word"].strip() not in FORBIDDEN_NAME_TERMS
    ]

    # âœ… ë¬¸ì¥ íŒ¨í„´ ê¸°ë°˜ í›„ë³´ ë³´ì™„
    names_from_pattern = extract_names_by_pattern(text)
    for name in names_from_pattern:
        if name not in names and name not in FORBIDDEN_NAME_TERMS:
            names.append(name)

    return names



def expand_variation_patterns(text: str, mapping: dict) -> str:
    for tag, base in mapping.items():
        prefix = r'[\s\(\["\']*'
        suffix = f"(?:{'|'.join(COMMON_SUFFIXES)})?"
        josa = f"(?:{'|'.join(COMMON_JOSA)})?"
        pattern = re.compile(rf'(?<![\wê°€-í£]){re.escape(base)}{suffix}{josa}(?![\wê°€-í£])', re.IGNORECASE)

        # âœ… ì¡°ì‚¬, í˜¸ì¹­ í¬í•¨ ì‹œ baseë§Œ íƒœê¹…í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ê·¸ëŒ€ë¡œ
        def replacer(m):
            matched = m.group(0)
            if base in matched:
                return matched.replace(base, tag)
            return matched

        text = pattern.sub(replacer, text)

    return text


def boost_mapping_from_context(text: str, mapping: dict) -> dict:
    updated = {}
    for tag, base in mapping.items():
        idx = text.find(tag)
        if idx == -1:
            updated[tag] = base
            continue

        window = text[max(0, idx - 100): idx + 100]

        # ì¡°ì‚¬ì™€ í˜¸ì¹­ì€ íƒìƒ‰ì—ë§Œ ì“°ê³ , ì €ì¥ì€ baseë§Œ
        suffix = f"(?:{'|'.join(COMMON_SUFFIXES)})?"
        josa = f"(?:{'|'.join(COMMON_JOSA)})?"
        pattern = re.compile(rf'({re.escape(base)}{suffix}{josa})', re.IGNORECASE)

        match = pattern.search(window)
        matched = match.group(1) if match else base

        # âœ… ë‹¨ì„œëŠ” ì¡°ì‚¬ í¬í•¨ëœ í‘œí˜„ì´ë”ë¼ë„, ì €ì¥ì€ í•­ìƒ ì´ë¦„ ë³¸ì²´
        if base in matched:
            updated[tag] = base
        else:
            updated[tag] = matched  # fallback (í¬ë°•í•œ ê²½ìš°)
    return updated




# âœ… ë¬¸ì¥ ë‹¨ì„œ ê¸°ë°˜ ì´ë¦„ ì¶”ì¶œ í•¨ìˆ˜
def extract_names_by_pattern(text):
    pattern_names = set()
    for pattern in EXPLICIT_NAME_PATTERNS:
        matches = re.findall(pattern, text)
        for match in matches:
            if isinstance(match, tuple):
                pattern_names.add(match[0])
            else:
                pattern_names.add(match)
    return list(pattern_names)


# âœ… ì´ë¦„ + í˜¸ì¹­/ì¡°ì‚¬ í¬í•¨ ë§ˆìŠ¤í‚¹ (ë™ì¼ì¸ë¬¼ í‘œí˜„ ë¬¶ì–´ì„œ ê³„ì¸µíƒœê¹…)
def mask_names_with_suffix_josa(original_text, names, start_counter=100):
    masked_text = original_text
    mapping = {}
    counter = start_counter

    # âœ… ìˆ˜ë™ ë§¤í•‘ ê¸°ë°˜ ì´ë¦„ ë™ì˜ì–´ (ì˜ˆ: "ì•„ìœ¤" â†’ "ì¡°ì•„ìœ¤")
    name_alias_dict = {
        "ì•„ìœ¤": "ì¡°ì•„ìœ¤",
        # í•„ìš” ì‹œ ì¶”ê°€ ê°€ëŠ¥
    }

    # âœ… ëŒ€í‘œì´ë¦„ìœ¼ë¡œ ê·¸ë£¹í•‘
    name_groups = {}
    for name in names:
        base_name = name_alias_dict.get(name, name)
        if base_name not in name_groups:
            name_groups[base_name] = []
        name_groups[base_name].append(name)

    # âœ… ê° ëŒ€í‘œì´ë¦„ë³„ íƒœê¹… ì§„í–‰
    for base_name, name_variants in name_groups.items():
        base_tag = f"N{counter:03d}"
        mapping[base_tag] = base_name
        suffix_pattern = f"(?:{'|'.join(COMMON_SUFFIXES)})?"
        josa_pattern = f"(?:{'|'.join(COMMON_JOSA)})?"
        pattern = re.compile(
            rf'(?<![\wê°€-í£])({"|".join(map(re.escape, name_variants))}{suffix_pattern}{josa_pattern})\b(?![\wê°€-í£])'
        )

        sub_counter = 1
        for match in pattern.finditer(masked_text):
            full_match = match.group(1)

            # âœ… 1. ëŒ€í‘œì´ë¦„ì€ ë§ˆì§€ë§‰ì— ì²˜ë¦¬
            if full_match == base_name:
                continue

            tag = f"{base_tag}-{sub_counter}"

            # âœ… 2. ì´ë¯¸ íƒœê·¸ê°€ ë“¤ì–´ê°„ ì¡°ê°ì´ë©´ ë¬´ì‹œ (ì¤‘ë³µ ë°©ì§€)
            if any(existing_tag in full_match for existing_tag in mapping.keys()):
                continue

            # âœ… ì¡°ì‚¬ë‚˜ í˜¸ì¹­ë§Œ ì˜ë¦° ê²½ìš° ë¬´ì‹œ (ì˜ˆ: 'ì´ë©°'ë§Œ ë‹¨ë… ë“±ì¥)
            if len(full_match.strip()) <= len(base_name):
                 continue


            # âœ… 4. ì¤‘ë³µ ë§¤í•‘ì´ë‚˜ í…ìŠ¤íŠ¸ì— ì´ë¯¸ ë“±ì¥í•œ íƒœê·¸ ë¬´ì‹œ
            if tag in masked_text or full_match in mapping.values():
                continue

            # âœ… 5. ì •ìƒì ì¸ ê²½ìš°ë§Œ íƒœê¹…
            mapping[tag] = base_name

            # âœ… 6. ë‹¨ì–´ ê²½ê³„ ê¸°ë°˜ ì•ˆì „ ì¹˜í™˜
            safe_pattern = re.compile(rf'(?<![\wê°€-í£]){re.escape(full_match)}(?![\wê°€-í£])')
            masked_text = safe_pattern.sub(
                lambda m: m.group(0).replace(base_name, tag),
                masked_text,
                count=1
            )

            sub_counter += 1

        # âœ… ëŒ€í‘œì´ë¦„ ë‹¨ë… ë§¤ì¹­ì€ ë§ˆì§€ë§‰ì— ì²˜ë¦¬
        pattern_base = re.compile(rf'(?<![\wê°€-í£])({re.escape(base_name)})(?![\wê°€-í£])')
        masked_text = pattern_base.sub(base_tag, masked_text)

        counter += 1


    return masked_text, mapping



def to_chosung(text: str) -> str:
    CHOSUNG_LIST = [chr(i) for i in range(0x1100, 0x1113)]
    result = ""
    for ch in text:
        if 'ê°€' <= ch <= 'í£':
            code = ord(ch) - ord('ê°€')
            cho = code // 588
            result += CHOSUNG_LIST[cho]
        else:
            result += ch
    return result

def sanitize_sensitive_info(text):
    # ğŸ“§ ì´ë©”ì¼
    text = re.sub(r"[\w\.-]+@[\w\.-]+", r"******@****", text)
    # ğŸ” ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸
    text = re.sub(r"(\d{6})[-](\d)\d{6}", r"*******-\2*****", text)
    # ğŸ“ ì „í™”ë²ˆí˜¸
    text = re.sub(r"(\d{3})-(\d{4})-(\d{4})", r"\1-****-\3", text)
    # ğŸ  ì£¼ì†Œ
    text = re.sub(r"(\d{1,3})ë²ˆì§€", r"***ë²ˆì§€", text)
    text = re.sub(r"(\d{1,3})ë™", r"***ë™", text)
    text = re.sub(r"(\d{1,4})í˜¸", r"****í˜¸", text)
    text = re.sub(r"([ê°€-í£]+(ëŒ€ë¡œ|ë¡œ|ê¸¸))\s?(\d+)(í˜¸|ë²ˆê¸¸|ê°€)?", r"\1 ***", text)
    text = re.sub(r"([ê°€-í£]{1,10})(ì€í–‰|ë™|ë¡œ|ê¸¸)\s?([\d\-]{4,})", lambda m: m.group(1) + m.group(2) + " " + re.sub(r"\d", "*", m.group(3)), text)
    # ğŸ’³ ìˆ«ìí˜• ì½”ë“œë“¤
    text = re.sub(r"(\d{2,6})[-]?(\d{2,6})[-]?(\d{2,6})", lambda m: f"{m.group(1)[:2]}{'*'*(len(m.group(1))-2)}{'*'*len(m.group(2))}{m.group(3)[-4:]}", text)
    text = re.sub(r"(\d{4})[- ]?(\d{4})[- ]?(\d{4})[- ]?(\d{4})", lambda m: f"{m.group(1)}-****-****-{m.group(4)}", text)
    # ğŸŒ IP
    text = re.sub(r"(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})", lambda m: f"{m.group(1)}.{m.group(2)}.*.*", text)
    # ğŸ“… ìƒë…„ì›”ì¼
    text = re.sub(r"(\d{4})ë…„ (\d{1,2})ì›” (\d{1,2})ì¼", r"19**ë…„ \2ì›” *ì¼", text)
    # ğŸ¢ ê¸°ê´€ëª…
    text = re.sub(r"\b(good neighbors|êµ¿ë„¤ì´ë²„ìŠ¤|ì‚¬íšŒë³µì§€ë²•ì¸ êµ¿ë„¤ì´ë²„ìŠ¤|gn)\b", "ìš°ë¦¬ë²•ì¸", text, flags=re.IGNORECASE)
    # ğŸ« í•™êµëª… ë§ˆìŠ¤í‚¹
    text = re.sub(r"([ê°€-í£]{2,20})(ì´ˆë“±í•™êµ|ì¤‘í•™êµ|ê³ ë“±í•™êµ|ëŒ€í•™êµ)", lambda m: to_chosung(m.group(1)) + m.group(2), text)
    # ğŸ¢ í•™ê³¼ ë§ˆìŠ¤í‚¹
    text = re.sub(r"([ê°€-í£]{2,20})í•™ê³¼", lambda m: to_chosung(m.group(1)) + "í•™ê³¼", text)
    # ğŸ“ í•™ë…„/ë°˜ ë§ˆìŠ¤í‚¹
    text = re.sub(r"(\d)í•™ë…„(\s?(\d)ë°˜)?", "*í•™ë…„ *ë°˜", text)
    return text

# âœ… í›„ì²˜ë¦¬: ì¡°ì‚¬/ì–´ë¯¸ê°€ ë¶™ì€ ê²½ìš°ì—ë„ ì´ë¦„ë§Œ ì •í™•íˆ ì¹˜í™˜
def final_name_remask_exact_only(original_text, masked_text, mapping_dict):
    for tag, name in mapping_dict.items():
        # âœ… ì´ë¦„ ë’¤ì— ì¡°ì‚¬/í˜¸ì¹­/ì–´ë¯¸ê°€ ë¶™ì€ ê²½ìš°ê¹Œì§€ í¬í•¨í•´ ì¹˜í™˜
        pattern = re.compile(rf'(?<![\wê°€-í£])({re.escape(name)})(?=[ê°€-í£]{0,4}|\W|$)')

        # âœ… ì´ë¦„ë§Œ íƒœê¹…í•˜ê³ , ë’¤ ì¡°ì‚¬/í˜¸ì¹­ì€ ìœ ì§€
        masked_text = pattern.sub(lambda m: m.group(0).replace(name, tag), masked_text)

    return masked_text




# âœ… ë¯¼ê°ì •ë³´ ì „ì²´ ë§ˆìŠ¤í‚¹ íŒŒì´í”„ë¼ì¸
def full_masking_pipeline(text):
    names = extract_names(text)
    # 1. ì´ë¦„ + í˜¸ì¹­/ì¡°ì‚¬ í¬í•¨ ì •ê·œì‹ ê¸°ë°˜ íƒœê¹…
    masked_text, mapping = mask_names_with_suffix_josa(text, names)
    # 2. í™•ì¥ í‘œí˜„ ë‚´ë¶€ ì¬ì¹˜í™˜ (ê¹€ì² ìˆ˜êµìˆ˜ë‹˜ê»˜ì„œ â†’ N100ê»˜ì„œ)
    masked_text = expand_variation_patterns(masked_text, mapping)
    # 3. ë§¤í•‘ ì •ë³´ë„ ë³´ì • (íƒœê·¸ ì£¼ë³€ì—ì„œ ê°€ì¥ ê¸´ í‘œí˜„ìœ¼ë¡œ ì¬ë§¤í•‘)
    mapping = boost_mapping_from_context(masked_text, mapping)
    # 4. ë¯¼ê°ì •ë³´ ì •ê·œì‹ ê¸°ë°˜ ë§ˆìŠ¤í‚¹
    sanitized = sanitize_sensitive_info(masked_text)
    # 5. í˜¹ì‹œ ë‹¤ì‹œ ì´ë¦„ì´ ì›ë¬¸ì— ë‚¨ì•˜ì„ ê²½ìš° ë³´ì •
    sanitized = final_name_remask_exact_only(text, sanitized, mapping)

    # 6. âœ… í…ìŠ¤íŠ¸ì— ì—†ëŠ” íƒœê·¸ëŠ” ë§¤í•‘ì—ì„œ ì œê±°
    mapping = {k: v for k, v in mapping.items() if k in sanitized}

    # 7. âœ… ì»¬ëŸ¬ ì¶œë ¥ìš©ìœ¼ë¡œëŠ” dict ìì²´ë¥¼ ë„˜ê²¨ì•¼ í•¨
    mapping_table = "\n".join([f"{k} â†’ {v}" for k, v in mapping.items()])

    return sanitized, mapping, mapping_table  # â† dict + í…ìŠ¤íŠ¸ ë‘˜ ë‹¤ ë¦¬í„´


def masking_tool(text, option=False):
    names = extract_names(text)
    masked_text, mapping = mask_names_with_suffix_josa(text, names)
    masked_text = expand_variation_patterns(masked_text, mapping)
    mapping = boost_mapping_from_context(masked_text, mapping)
    sanitized = sanitize_sensitive_info(masked_text)
    sanitized = final_name_remask_exact_only(sanitized, mapping)

    # âœ… ë§¤í•‘ ì •ë³´ í•œ ì¤„ë¡œ ì •ë¦¬
    mapping_line = " / ".join([f"{k} {v}" for k, v in mapping.items()])

    # âœ… ì¶œë ¥ì€ output ë°•ìŠ¤ì— ì „ë¶€ í‘œì‹œ
    full_output = f"{sanitized}\n\n{mapping_line}"
    return {
        "ê²°ê³¼": full_output,
        "ì •ë³´": ""
    }

